{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e5da49-03dc-4861-9a00-b86b74192776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Paths\n",
    "data_dir = r'D:\\raj\\catract detection\\processed_images'\n",
    "model_save_path = 'cataract_model.pth'\n",
    "\n",
    "# Parameters\n",
    "batch_size = 16\n",
    "input_size = 224\n",
    "epochs = 3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data Transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load Datasets\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "    for x in ['train', 'test']\n",
    "}\n",
    "\n",
    "# Optional: Reduce dataset size for quick testing\n",
    "reduce_data = True\n",
    "if reduce_data:\n",
    "    reduced_size = 50\n",
    "    image_datasets = {\n",
    "        phase: Subset(dataset, random.sample(range(len(dataset)), min(len(dataset), reduced_size)))\n",
    "        for phase, dataset in image_datasets.items()\n",
    "    }\n",
    "\n",
    "# Data Loaders\n",
    "dataloaders = {\n",
    "    x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n",
    "    for x in ['train', 'test']\n",
    "}\n",
    "\n",
    "# Class names\n",
    "class_names = ['cataract', 'normal']\n",
    "\n",
    "# Model\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch+1}/{epochs}\\n{\"-\"*20}')\n",
    "    model.train()\n",
    "    running_loss, running_corrects = 0.0, 0\n",
    "\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloaders['train'].dataset)\n",
    "    epoch_acc = running_corrects.double() / len(dataloaders['train'].dataset)\n",
    "\n",
    "    print(f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f'Model saved to {model_save_path}')\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(model):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['test']:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    # Dynamically handle class names\n",
    "    unique_labels = np.unique(all_labels)\n",
    "    used_class_names = [class_names[label] for label in unique_labels]\n",
    "\n",
    "    print(classification_report(all_labels, all_preds, target_names=used_class_names))\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=used_class_names, yticklabels=used_class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    if len(unique_labels) > 1:\n",
    "        roc_score = roc_auc_score(all_labels, all_preds)\n",
    "        print(f'ROC AUC Score: {roc_score:.4f}')\n",
    "    else:\n",
    "        print('ROC AUC Score: Cannot be computed (only one class present)')\n",
    "\n",
    "evaluate_model(model)\n",
    "\n",
    "# Grad-CAM Visualization\n",
    "def show_gradcam(model, image_path):\n",
    "    model.eval()\n",
    "\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    transform = data_transforms['test']\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    # Hook the gradients\n",
    "    gradients = []\n",
    "    activations = []\n",
    "\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients.append(grad_output[0])\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output)\n",
    "\n",
    "    final_conv = None\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            final_conv = module\n",
    "\n",
    "    if final_conv is None:\n",
    "        print(\"No convolution layer found!\")\n",
    "        return\n",
    "\n",
    "    forward_handle = final_conv.register_forward_hook(forward_hook)\n",
    "    backward_handle = final_conv.register_backward_hook(backward_hook)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(input_tensor)\n",
    "    pred_class = output.argmax().item()\n",
    "\n",
    "    # Backward pass\n",
    "    model.zero_grad()\n",
    "    output[0, pred_class].backward()\n",
    "\n",
    "    # Process Grad-CAM\n",
    "    gradients_ = gradients[0].cpu().numpy()[0]\n",
    "    activations_ = activations[0].detach().cpu().numpy()[0]\n",
    "    weights = np.mean(gradients_, axis=(1, 2))\n",
    "\n",
    "    cam = np.zeros(activations_.shape[1:], dtype=np.float32)\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * activations_[i, :, :]\n",
    "\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max() if cam.max() != 0 else cam\n",
    "    cam = np.uint8(cam * 255)\n",
    "\n",
    "    # Resize and overlay\n",
    "    cam = Image.fromarray(cam).resize(img.size, Image.BILINEAR)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(cam, cmap='jet', alpha=0.5)\n",
    "    plt.title(f'Grad-CAM for class: {class_names[pred_class]}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Clean up hooks\n",
    "    forward_handle.remove()\n",
    "    backward_handle.remove()\n",
    "\n",
    "# Example: show_gradcam(model, r'D:\\raj\\catract detection\\processed_images\\test\\cataract\\sample.jpg')\n",
    "\n",
    "# Inference function\n",
    "def predict_image(model, image_path):\n",
    "    model.eval()\n",
    "\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    transform = data_transforms['test']\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    output = model(input_tensor)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    print(f'Predicted class: {class_names[pred.item()]}')\n",
    "\n",
    "# Example: predict_image(model, r'D:\\raj\\catract detection\\processed_images\\test\\normal\\sample.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe25c62-9b15-409b-8631-ffa085e9476b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c8c49-552b-4b47-90b2-8ee14df1a14e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
